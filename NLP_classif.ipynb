{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5QBAxh3L49z11pNBcJzH+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e0425016e0d9448ca5ddee028a1a86cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb14b782fc304c08848dc9b7f60ee793","IPY_MODEL_435c7fd037c644c7ae36ae3b85714706","IPY_MODEL_04b92e7105f44b26b133174bb478f9f3"],"layout":"IPY_MODEL_141ed39f44a14f5e9221c7bfeabc87b3"}},"eb14b782fc304c08848dc9b7f60ee793":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e9f927434a44b8988be6f3ee11c9bf","placeholder":"​","style":"IPY_MODEL_0baf62b2b2ab49ee87fc59373ecaf02f","value":"tokenizer_config.json: 100%"}},"435c7fd037c644c7ae36ae3b85714706":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbb3d93b9d5545ceabc1810e24173e54","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3eea562f318c494687c290b8df3d618d","value":25}},"04b92e7105f44b26b133174bb478f9f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52f197e6de824b068a476c4c60b436df","placeholder":"​","style":"IPY_MODEL_19160925990b40ce9315762a268fc605","value":" 25.0/25.0 [00:00&lt;00:00, 1.64kB/s]"}},"141ed39f44a14f5e9221c7bfeabc87b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e9f927434a44b8988be6f3ee11c9bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0baf62b2b2ab49ee87fc59373ecaf02f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbb3d93b9d5545ceabc1810e24173e54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eea562f318c494687c290b8df3d618d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52f197e6de824b068a476c4c60b436df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19160925990b40ce9315762a268fc605":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fc83f175afe488db20ceffc0e1a4d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7da7a100a285495f9d1a0b3502ea1863","IPY_MODEL_90bc0519d4464bcebd14031618d24d51","IPY_MODEL_e103d499d5bf48379db409a94f0b01d2"],"layout":"IPY_MODEL_2e95b6eb647b4818b3751da821681cf3"}},"7da7a100a285495f9d1a0b3502ea1863":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a354d5797c41a29da09071fbccf75a","placeholder":"​","style":"IPY_MODEL_1b60bb5feaf54c22ae256b30619c8197","value":"vocab.json: 100%"}},"90bc0519d4464bcebd14031618d24d51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c604f82b6ae446b8702c034eefdb1c1","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_646426b63de5445f8ea2b84f08097a36","value":898823}},"e103d499d5bf48379db409a94f0b01d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dc181759eea4cfebcb60a2e32862c5b","placeholder":"​","style":"IPY_MODEL_a0b7bc73206f41a9a74b1bbae47bf837","value":" 899k/899k [00:00&lt;00:00, 10.8MB/s]"}},"2e95b6eb647b4818b3751da821681cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a354d5797c41a29da09071fbccf75a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b60bb5feaf54c22ae256b30619c8197":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c604f82b6ae446b8702c034eefdb1c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646426b63de5445f8ea2b84f08097a36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8dc181759eea4cfebcb60a2e32862c5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b7bc73206f41a9a74b1bbae47bf837":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c7dc2904d374431ad326975737d73a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d13629a2495d4b66b066d5580100394c","IPY_MODEL_de14dc0a6d594e7ea2dcc4446e913d14","IPY_MODEL_a983146789e240b3bc30ff087b8a17d7"],"layout":"IPY_MODEL_0d87427459e1487881074bf27d440ab5"}},"d13629a2495d4b66b066d5580100394c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55346004b7e54be5aac47594ef9ab0b9","placeholder":"​","style":"IPY_MODEL_aa11b67ee88b4df59111712a6ec545c7","value":"merges.txt: 100%"}},"de14dc0a6d594e7ea2dcc4446e913d14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ea8e34ad7a5402fb59e061c9990b0d0","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fba04a5559774cabb29f90aca03aafa3","value":456318}},"a983146789e240b3bc30ff087b8a17d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c85207f6fcae45799242389d0fb38e16","placeholder":"​","style":"IPY_MODEL_9de06decbf6f4655b6dcb50fe9681dd9","value":" 456k/456k [00:00&lt;00:00, 8.63MB/s]"}},"0d87427459e1487881074bf27d440ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55346004b7e54be5aac47594ef9ab0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa11b67ee88b4df59111712a6ec545c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ea8e34ad7a5402fb59e061c9990b0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fba04a5559774cabb29f90aca03aafa3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c85207f6fcae45799242389d0fb38e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de06decbf6f4655b6dcb50fe9681dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23743fcd44aa41b1843347682f401977":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2618421ce14648ffb3980301c2ce0efb","IPY_MODEL_e3fc7831fe334cd7a5429d563ec6dd56","IPY_MODEL_618f09db28e74564bd3ea3a8b7203241"],"layout":"IPY_MODEL_b58c59a2fbff45a49dfcd6eb06dbe439"}},"2618421ce14648ffb3980301c2ce0efb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ad49c4556424c07b640ecfb17bd50a4","placeholder":"​","style":"IPY_MODEL_290a559ef4654dcb81d61a967236d2b5","value":"tokenizer.json: 100%"}},"e3fc7831fe334cd7a5429d563ec6dd56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b6253f73f424104b61904baba38427d","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19c50d25abfb4bbb92e8c7c992145190","value":1355863}},"618f09db28e74564bd3ea3a8b7203241":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aaa0360f484460a986c8ae85b7f601d","placeholder":"​","style":"IPY_MODEL_f05b6a9bbdc44b529f7b644ea0ee1b0e","value":" 1.36M/1.36M [00:00&lt;00:00, 23.5MB/s]"}},"b58c59a2fbff45a49dfcd6eb06dbe439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ad49c4556424c07b640ecfb17bd50a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"290a559ef4654dcb81d61a967236d2b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b6253f73f424104b61904baba38427d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19c50d25abfb4bbb92e8c7c992145190":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2aaa0360f484460a986c8ae85b7f601d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f05b6a9bbdc44b529f7b644ea0ee1b0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93b7c7a880f04bb78baddf4c18443179":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6f35e5299674aa1a4e6413a9ea74a78","IPY_MODEL_841988ced2a14032b07ed5ed4969b60b","IPY_MODEL_fe333090537c4ce9be04e172e5823759"],"layout":"IPY_MODEL_c4e9fe34910847fcbb2d2cb9751cdadb"}},"b6f35e5299674aa1a4e6413a9ea74a78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e765cd2f0c5a47e186e3b7970a9fd03a","placeholder":"​","style":"IPY_MODEL_9fcc861219694cabb671b2ef92770e0a","value":"config.json: 100%"}},"841988ced2a14032b07ed5ed4969b60b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e5ffd38c2ff4f41a50c83694db74b20","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0622b2ba4444d12bb5700b34c88766e","value":481}},"fe333090537c4ce9be04e172e5823759":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4101a407ec24dbfac14260f64e30f31","placeholder":"​","style":"IPY_MODEL_27b4549e302843adb06d67c8470a5888","value":" 481/481 [00:00&lt;00:00, 44.7kB/s]"}},"c4e9fe34910847fcbb2d2cb9751cdadb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e765cd2f0c5a47e186e3b7970a9fd03a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fcc861219694cabb671b2ef92770e0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e5ffd38c2ff4f41a50c83694db74b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0622b2ba4444d12bb5700b34c88766e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4101a407ec24dbfac14260f64e30f31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27b4549e302843adb06d67c8470a5888":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d85061f4ca144ddada7623ab26707e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7bac1d48edbe42898a03ac92ee754f06","IPY_MODEL_35689b1b7bb34ee6a04145f2eadd1d48","IPY_MODEL_5c1b1848e8c3448588a97f34662b80de"],"layout":"IPY_MODEL_e16c9dde23e24a1498e37f989de9cdf4"}},"7bac1d48edbe42898a03ac92ee754f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8da79cdf1c8849acafb926af30409af2","placeholder":"​","style":"IPY_MODEL_72401ee95e944fd8b8d04584bc0a17d6","value":"model.safetensors: 100%"}},"35689b1b7bb34ee6a04145f2eadd1d48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b662d20a93cc46eea2ba3d866d48a917","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0397a9db2b6a46b9b090eb21f54accac","value":498818054}},"5c1b1848e8c3448588a97f34662b80de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa5b3c4473424faf8bbbd12a2b6ca9d5","placeholder":"​","style":"IPY_MODEL_a18aa919dbb842c8bd4ae3c08725d63d","value":" 499M/499M [00:05&lt;00:00, 77.4MB/s]"}},"e16c9dde23e24a1498e37f989de9cdf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8da79cdf1c8849acafb926af30409af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72401ee95e944fd8b8d04584bc0a17d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b662d20a93cc46eea2ba3d866d48a917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0397a9db2b6a46b9b090eb21f54accac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa5b3c4473424faf8bbbd12a2b6ca9d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a18aa919dbb842c8bd4ae3c08725d63d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oU3xrOiijtz","executionInfo":{"status":"ok","timestamp":1742489428894,"user_tz":-60,"elapsed":31014,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}},"outputId":"21ba5ae2-d9b0-4d16-83f4-0f3ac5c5029c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import pickle\n","import argparse\n","import torch\n","from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import classification_report, f1_score\n","from sklearn.utils.class_weight import compute_class_weight\n","from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n","from transformers import RobertaForSequenceClassification, RobertaTokenizerFast\n","\n","import os\n","import random\n","#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wseof8CLjMjG","executionInfo":{"status":"ok","timestamp":1742489539037,"user_tz":-60,"elapsed":22880,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}},"outputId":"7f5fe868-03d4-4907-c357-e33d265f7bc3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["class HateDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n"],"metadata":{"id":"rTC0z6NsjO-T","executionInfo":{"status":"ok","timestamp":1742489545339,"user_tz":-60,"elapsed":11,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class WeightedTrainer(Trainer):\n","    def __init__(self, class_weights, **kwargs):\n","       # self.class_weights = torch.FloatTensor(class_weights)\n","        self.weighted_loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights)).to(DEVICE)\n","        super().__init__(**kwargs)\n","\n","    # def compute_loss(self, model, inputs, return_outputs=False):\n","    #     labels = inputs.pop(\"labels\")\n","    #     outputs = model(**inputs)\n","    #     logits = outputs[0]\n","    #     loss = self.weighted_loss(logits, labels)\n","    #     if return_outputs:\n","    #         return loss, outputs\n","    #     else:\n","    #         return loss\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs[0]\n","        loss = self.weighted_loss(logits, labels)\n","        if return_outputs:\n","            return loss, outputs\n","        return loss\n"],"metadata":{"id":"T-los-AOjS5y","executionInfo":{"status":"ok","timestamp":1742489547782,"user_tz":-60,"elapsed":39,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def create_datasets(data_dir):\n","\n","    train_df = pd.read_csv(data_dir + \"/train.csv\",engine=\"python\")\n","    train_df = train_df.dropna()\n","    train_df = train_df.dropna(subset=['label'])\n","    valid_df = pd.read_csv(data_dir + \"/valid.csv\",engine=\"python\")\n","    valid_df = valid_df.dropna()\n","    valid_df = valid_df.dropna(subset=['label'])\n","    test_df = pd.read_csv(data_dir + \"/test.csv\",engine=\"python\")\n","    test_df = test_df.dropna()\n","    test_df = test_df.dropna(subset=['label'])\n","\n","\n","    train_texts = train_df['text'].astype(\"string\").tolist()\n","    valid_texts = valid_df['text'].astype(\"string\").tolist()\n","    test_texts = test_df['text'].astype(\"string\").tolist()\n","\n","    train_labels = train_df['label'].astype(\"int\").tolist()\n","    valid_labels = valid_df['label'].astype(\"int\").tolist()\n","    test_labels = test_df['label'].astype(\"int\").tolist()\n","\n","    # tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","    # tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","    tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n","    # add special tokens for URLs, emojis and mentions (--> see pre-processing)\n","    special_tokens_dict = {'additional_special_tokens': ['[USER]', '[EMOJI]', '[URL]']}\n","    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n","\n","    # train_encodings = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n","    train_encodings = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\")\n","    # valid_encodings = tokenizer(valid_texts, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n","    valid_encodings = tokenizer(valid_texts, padding=True, truncation=True, return_tensors=\"pt\")\n","    test_encodings = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","    train_dataset = HateDataset(train_encodings, train_labels)\n","    valid_dataset = HateDataset(valid_encodings, valid_labels)\n","    test_dataset = HateDataset(test_encodings, test_labels)\n","\n","    return train_dataset, valid_dataset, test_dataset, len(tokenizer)"],"metadata":{"id":"lgOPDWoLjUYq","executionInfo":{"status":"ok","timestamp":1742489550347,"user_tz":-60,"elapsed":20,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def calculate_class_weights(data_dir):\n","    dataset = pd.read_csv(data_dir + \"/train.csv\",engine=\"python\")\n","    dataset = dataset.dropna(subset=['label'])\n","    train_labels = dataset.label.to_numpy()\n","    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n","    print(\"class weights are {}\".format(class_weights))\n","    return class_weights\n","\n","\n","def train_model(train_dataset, valid_dataset, tok_len,  class_weights, output_dir, learning_rate, num_epochs, batch_size):\n","    training_args = TrainingArguments(\n","        save_steps=5000,\n","        output_dir=output_dir,  # output directory\n","        num_train_epochs=num_epochs,  # total number of training epochs\n","        per_device_train_batch_size=batch_size,  # batch size per device during training\n","        per_device_eval_batch_size=64,  # batch size for evaluation\n","        warmup_steps=1000,  # number of warmup steps for learning rate scheduler\n","        weight_decay=0.01,  # strength of weight decay\n","        learning_rate=learning_rate,\n","        seed=123,\n","        logging_dir=os.path.join(output_dir, \"logs\"),\n","        logging_steps=50,          # log every 50 steps\n","        eval_strategy=\"steps\",\n","        eval_steps=250,\n","    )\n","\n","    # model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","    # model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n","    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n","    model = model.to(DEVICE)\n","    model.resize_token_embeddings(tok_len)\n","\n","    trainer = WeightedTrainer(\n","        model=model,\n","        class_weights=class_weights,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=valid_dataset\n","    )\n","\n","    try:\n","        trainer.train(resume_from_checkpoint=True)\n","        print(\"resuming from checkpoint...\")\n","    except ValueError:\n","        print(\"No checkpoints found. training from scratch...\")\n","        trainer.train()\n","\n","    return trainer"],"metadata":{"id":"nMP8Wxz5jY3U","executionInfo":{"status":"ok","timestamp":1742489552587,"user_tz":-60,"elapsed":37,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dir = \"/content/drive/MyDrive/NLP/\"\n","dataset_dir = dir + \"Data/\"\n","# datasets = [\"CAD_hate\", \"CAD_abuse\", \"Founta_hate\", \"Founta_abuse\", \"Davidson_hate\", \"Davidson_abuse\"]\n","# datasets = [\"CAD_hate\", \"CAD_abuse\"]\n","# datasets = [\"CAD_hate\", \"CAD_abuse\", \"Davidson_hate\", \"Davidson_abuse\", \"Dynamic_hate\", \"Measuring_dat_hate\", \"Measuring_dat_abuse\"]\n","datasets = [ \"Dynamic_hate\", \"Measuring_dat_hate\", \"Measuring_dat_abuse\"]\n","\n","output_dir = dir + \"Weights/eng_classif_RoBerta/\"\n","num_epochs = 5\n","batch_size = 16\n","learning_rate = 5e-5\n","\n","for dataset in datasets:\n","    dd_dir = dataset_dir + dataset\n","    oo_dir = output_dir + dataset\n","\n","    train_dataset, valid_dataset, test_dataset, tok_len = create_datasets(dd_dir)\n","    class_weights = calculate_class_weights(dd_dir)\n","\n","    trainer = train_model(train_dataset,\n","                          valid_dataset,\n","                          tok_len,\n","                          class_weights,\n","                          oo_dir,\n","                          learning_rate,\n","                          num_epochs,\n","                          batch_size)\n","\n","    trainer.save_model(oo_dir)\n","\n","    print(\"Training done, evaluating...\")\n","    valid_preds = np.argmax(trainer.predict(valid_dataset)[0], axis=1) #should be numpy ndarray\n","    valid_labels = np.array(valid_dataset.labels)\n","\n","    cls_report_valid = classification_report(valid_labels, valid_preds, output_dict=True)\n","    pickle.dump(cls_report_valid, open(oo_dir + \"/cls_report_valid.pickle\", \"wb\"))\n","\n","    test_preds = np.argmax(trainer.predict(test_dataset)[0], axis=1)\n","    test_labels = np.array(test_dataset.labels)\n","\n","    cls_report_test = classification_report(test_labels, test_preds, output_dict=True)\n","    pickle.dump(cls_report_test, open(oo_dir + \"/cls_report_test.pickle\", \"wb\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QB-YSXfwje4x","outputId":"3eeff39b-0e43-4f57-f7a9-ae566a226752","collapsed":true,"executionInfo":{"status":"error","timestamp":1742472007113,"user_tz":-60,"elapsed":55731118,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["class weights are [1.08416754 0.92795941]\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["No checkpoints found. training from scratch...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10290/10290 5:04:57, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.667700</td>\n","      <td>0.614588</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.540200</td>\n","      <td>0.502172</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.532000</td>\n","      <td>0.486996</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.539600</td>\n","      <td>0.477900</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.521000</td>\n","      <td>0.461424</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.538700</td>\n","      <td>0.446005</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.496700</td>\n","      <td>0.439376</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.477600</td>\n","      <td>0.432961</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.406400</td>\n","      <td>0.438442</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.403800</td>\n","      <td>0.454144</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.405100</td>\n","      <td>0.402663</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.404300</td>\n","      <td>0.407000</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.340300</td>\n","      <td>0.452203</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.387800</td>\n","      <td>0.393050</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.392800</td>\n","      <td>0.457827</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.371700</td>\n","      <td>0.397905</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.277100</td>\n","      <td>0.462158</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.335000</td>\n","      <td>0.418906</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.296400</td>\n","      <td>0.454993</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.275200</td>\n","      <td>0.497827</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.277300</td>\n","      <td>0.434018</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.280900</td>\n","      <td>0.497493</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.287300</td>\n","      <td>0.437480</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.287800</td>\n","      <td>0.436382</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.184500</td>\n","      <td>0.646072</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.216300</td>\n","      <td>0.512192</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.184300</td>\n","      <td>0.728774</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.157800</td>\n","      <td>0.689636</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.178800</td>\n","      <td>0.575270</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.171100</td>\n","      <td>0.565520</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.194700</td>\n","      <td>0.566501</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.194100</td>\n","      <td>0.525373</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.145400</td>\n","      <td>0.660246</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.153700</td>\n","      <td>0.758084</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.159900</td>\n","      <td>0.791688</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.165700</td>\n","      <td>0.783335</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.125600</td>\n","      <td>0.752243</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.135400</td>\n","      <td>0.785407</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.114400</td>\n","      <td>0.859706</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.144600</td>\n","      <td>0.837432</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.161700</td>\n","      <td>0.814140</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training done, evaluating...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["class weights are [0.78348698 1.38187471]\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["No checkpoints found. training from scratch...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33890' max='33890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33890/33890 8:46:15, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.419900</td>\n","      <td>0.325069</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.352600</td>\n","      <td>0.357508</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.347100</td>\n","      <td>0.318284</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.353500</td>\n","      <td>0.384390</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.394200</td>\n","      <td>0.367367</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.385800</td>\n","      <td>0.359033</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.349700</td>\n","      <td>0.379709</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.430700</td>\n","      <td>0.344701</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.365600</td>\n","      <td>0.345894</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.362000</td>\n","      <td>0.352684</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.348900</td>\n","      <td>0.327045</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.322500</td>\n","      <td>0.328790</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.347400</td>\n","      <td>0.359501</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.374700</td>\n","      <td>0.372745</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.324600</td>\n","      <td>0.307379</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.388300</td>\n","      <td>0.313123</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.373900</td>\n","      <td>0.382854</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.367400</td>\n","      <td>0.419140</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.323000</td>\n","      <td>0.369172</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.377700</td>\n","      <td>0.357821</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.551900</td>\n","      <td>0.693067</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.383600</td>\n","      <td>0.431208</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.495800</td>\n","      <td>0.438449</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.582800</td>\n","      <td>0.517934</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.455600</td>\n","      <td>0.429142</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.501000</td>\n","      <td>0.520471</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.403100</td>\n","      <td>0.380964</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.382400</td>\n","      <td>0.383890</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.385900</td>\n","      <td>0.388604</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.466000</td>\n","      <td>0.445559</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.414600</td>\n","      <td>0.477975</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.380300</td>\n","      <td>0.361864</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.341400</td>\n","      <td>0.483206</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.380300</td>\n","      <td>0.386116</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.638500</td>\n","      <td>0.490845</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.514100</td>\n","      <td>0.477072</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.443900</td>\n","      <td>0.466475</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.425800</td>\n","      <td>0.450700</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.473500</td>\n","      <td>0.430712</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.427200</td>\n","      <td>0.458435</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.449500</td>\n","      <td>0.425629</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.471900</td>\n","      <td>0.442614</td>\n","    </tr>\n","    <tr>\n","      <td>10750</td>\n","      <td>0.457200</td>\n","      <td>0.451140</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.439600</td>\n","      <td>0.456609</td>\n","    </tr>\n","    <tr>\n","      <td>11250</td>\n","      <td>0.465500</td>\n","      <td>0.450916</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.508400</td>\n","      <td>0.467629</td>\n","    </tr>\n","    <tr>\n","      <td>11750</td>\n","      <td>0.441200</td>\n","      <td>0.481902</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.490000</td>\n","      <td>0.497956</td>\n","    </tr>\n","    <tr>\n","      <td>12250</td>\n","      <td>0.497400</td>\n","      <td>0.499728</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.514200</td>\n","      <td>0.497305</td>\n","    </tr>\n","    <tr>\n","      <td>12750</td>\n","      <td>0.754000</td>\n","      <td>0.535904</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.645400</td>\n","      <td>0.667813</td>\n","    </tr>\n","    <tr>\n","      <td>13250</td>\n","      <td>0.572800</td>\n","      <td>0.620602</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.535500</td>\n","      <td>0.559243</td>\n","    </tr>\n","    <tr>\n","      <td>13750</td>\n","      <td>0.484800</td>\n","      <td>0.485917</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.679700</td>\n","      <td>0.656100</td>\n","    </tr>\n","    <tr>\n","      <td>14250</td>\n","      <td>0.669900</td>\n","      <td>0.665605</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.696000</td>\n","      <td>0.694240</td>\n","    </tr>\n","    <tr>\n","      <td>14750</td>\n","      <td>0.694600</td>\n","      <td>0.701777</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.695500</td>\n","      <td>0.693209</td>\n","    </tr>\n","    <tr>\n","      <td>15250</td>\n","      <td>0.695200</td>\n","      <td>0.695494</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.697800</td>\n","      <td>0.699756</td>\n","    </tr>\n","    <tr>\n","      <td>15750</td>\n","      <td>0.677100</td>\n","      <td>0.667649</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.695000</td>\n","      <td>0.693549</td>\n","    </tr>\n","    <tr>\n","      <td>16250</td>\n","      <td>0.692500</td>\n","      <td>0.694193</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.591400</td>\n","      <td>0.626931</td>\n","    </tr>\n","    <tr>\n","      <td>16750</td>\n","      <td>0.437300</td>\n","      <td>0.477167</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.463900</td>\n","      <td>0.428157</td>\n","    </tr>\n","    <tr>\n","      <td>17250</td>\n","      <td>0.477200</td>\n","      <td>0.437713</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.408500</td>\n","      <td>0.420887</td>\n","    </tr>\n","    <tr>\n","      <td>17750</td>\n","      <td>0.412400</td>\n","      <td>0.430327</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.522100</td>\n","      <td>0.564219</td>\n","    </tr>\n","    <tr>\n","      <td>18250</td>\n","      <td>0.564800</td>\n","      <td>0.554311</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.455500</td>\n","      <td>0.450156</td>\n","    </tr>\n","    <tr>\n","      <td>18750</td>\n","      <td>0.373500</td>\n","      <td>0.440640</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.409900</td>\n","      <td>0.433810</td>\n","    </tr>\n","    <tr>\n","      <td>19250</td>\n","      <td>0.429100</td>\n","      <td>0.443353</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.487800</td>\n","      <td>0.432296</td>\n","    </tr>\n","    <tr>\n","      <td>19750</td>\n","      <td>0.465400</td>\n","      <td>0.447805</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.449400</td>\n","      <td>0.448763</td>\n","    </tr>\n","    <tr>\n","      <td>20250</td>\n","      <td>0.439700</td>\n","      <td>0.444811</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.439400</td>\n","      <td>0.446106</td>\n","    </tr>\n","    <tr>\n","      <td>20750</td>\n","      <td>0.417400</td>\n","      <td>0.452555</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.450300</td>\n","      <td>0.454217</td>\n","    </tr>\n","    <tr>\n","      <td>21250</td>\n","      <td>0.511500</td>\n","      <td>0.471541</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.527500</td>\n","      <td>0.515945</td>\n","    </tr>\n","    <tr>\n","      <td>21750</td>\n","      <td>0.506200</td>\n","      <td>0.495467</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.542400</td>\n","      <td>0.531579</td>\n","    </tr>\n","    <tr>\n","      <td>22250</td>\n","      <td>0.541300</td>\n","      <td>0.514098</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.540000</td>\n","      <td>0.530070</td>\n","    </tr>\n","    <tr>\n","      <td>22750</td>\n","      <td>0.494300</td>\n","      <td>0.511240</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.463700</td>\n","      <td>0.519729</td>\n","    </tr>\n","    <tr>\n","      <td>23250</td>\n","      <td>0.512500</td>\n","      <td>0.517451</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.505300</td>\n","      <td>0.512585</td>\n","    </tr>\n","    <tr>\n","      <td>23750</td>\n","      <td>0.508100</td>\n","      <td>0.465814</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.433700</td>\n","      <td>0.425947</td>\n","    </tr>\n","    <tr>\n","      <td>24250</td>\n","      <td>0.431000</td>\n","      <td>0.435600</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.498200</td>\n","      <td>0.493111</td>\n","    </tr>\n","    <tr>\n","      <td>24750</td>\n","      <td>0.478400</td>\n","      <td>0.455365</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.407500</td>\n","      <td>0.468287</td>\n","    </tr>\n","    <tr>\n","      <td>25250</td>\n","      <td>0.441600</td>\n","      <td>0.461263</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.457500</td>\n","      <td>0.464687</td>\n","    </tr>\n","    <tr>\n","      <td>25750</td>\n","      <td>0.461100</td>\n","      <td>0.458672</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.474100</td>\n","      <td>0.459333</td>\n","    </tr>\n","    <tr>\n","      <td>26250</td>\n","      <td>0.441000</td>\n","      <td>0.459924</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.486000</td>\n","      <td>0.458780</td>\n","    </tr>\n","    <tr>\n","      <td>26750</td>\n","      <td>0.498100</td>\n","      <td>0.459341</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.437600</td>\n","      <td>0.465845</td>\n","    </tr>\n","    <tr>\n","      <td>27250</td>\n","      <td>0.433900</td>\n","      <td>0.454506</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>0.474400</td>\n","      <td>0.451869</td>\n","    </tr>\n","    <tr>\n","      <td>27750</td>\n","      <td>0.465700</td>\n","      <td>0.449990</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>0.467200</td>\n","      <td>0.436913</td>\n","    </tr>\n","    <tr>\n","      <td>28250</td>\n","      <td>0.441300</td>\n","      <td>0.447298</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>0.454200</td>\n","      <td>0.456917</td>\n","    </tr>\n","    <tr>\n","      <td>28750</td>\n","      <td>0.419100</td>\n","      <td>0.440227</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>0.449400</td>\n","      <td>0.438933</td>\n","    </tr>\n","    <tr>\n","      <td>29250</td>\n","      <td>0.420000</td>\n","      <td>0.442375</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>0.421600</td>\n","      <td>0.449362</td>\n","    </tr>\n","    <tr>\n","      <td>29750</td>\n","      <td>0.401700</td>\n","      <td>0.444687</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>0.440000</td>\n","      <td>0.439720</td>\n","    </tr>\n","    <tr>\n","      <td>30250</td>\n","      <td>0.435600</td>\n","      <td>0.443396</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>0.368800</td>\n","      <td>0.433650</td>\n","    </tr>\n","    <tr>\n","      <td>30750</td>\n","      <td>0.451400</td>\n","      <td>0.434961</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>0.398300</td>\n","      <td>0.431324</td>\n","    </tr>\n","    <tr>\n","      <td>31250</td>\n","      <td>0.416900</td>\n","      <td>0.427683</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>0.423200</td>\n","      <td>0.428926</td>\n","    </tr>\n","    <tr>\n","      <td>31750</td>\n","      <td>0.472100</td>\n","      <td>0.429170</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>0.415500</td>\n","      <td>0.431590</td>\n","    </tr>\n","    <tr>\n","      <td>32250</td>\n","      <td>0.441600</td>\n","      <td>0.426969</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>0.429500</td>\n","      <td>0.429381</td>\n","    </tr>\n","    <tr>\n","      <td>32750</td>\n","      <td>0.404000</td>\n","      <td>0.426691</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>0.426500</td>\n","      <td>0.425134</td>\n","    </tr>\n","    <tr>\n","      <td>33250</td>\n","      <td>0.410600</td>\n","      <td>0.426108</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>0.429500</td>\n","      <td>0.424976</td>\n","    </tr>\n","    <tr>\n","      <td>33750</td>\n","      <td>0.443900</td>\n","      <td>0.424468</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training done, evaluating...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["class weights are [0.90415208 1.11857903]\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["No checkpoints found. training from scratch...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5588' max='33890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 5588/33890 1:29:10 < 7:31:46, 1.04 it/s, Epoch 0.82/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>0.374800</td>\n","      <td>0.340149</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.348500</td>\n","      <td>0.351417</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.361100</td>\n","      <td>0.366492</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.371600</td>\n","      <td>0.362881</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.376900</td>\n","      <td>0.377125</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.372400</td>\n","      <td>0.367065</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.343500</td>\n","      <td>0.410097</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.354500</td>\n","      <td>0.338106</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.368400</td>\n","      <td>0.395451</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.299100</td>\n","      <td>0.449498</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.323100</td>\n","      <td>0.341684</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.364300</td>\n","      <td>0.387305</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.373000</td>\n","      <td>0.314509</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.332800</td>\n","      <td>0.338413</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.372100</td>\n","      <td>0.381459</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.364700</td>\n","      <td>0.352568</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.345200</td>\n","      <td>0.343277</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.371600</td>\n","      <td>0.324773</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.340100</td>\n","      <td>0.305134</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.397900</td>\n","      <td>0.344969</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.356100</td>\n","      <td>0.346131</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.374900</td>\n","      <td>0.360741</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-10a43011f169>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, valid_dataset, tok_len, class_weights, output_dir, learning_rate, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming from checkpoint...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No valid checkpoint found in output directory ({args.output_dir})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No valid checkpoint found in output directory (/content/drive/MyDrive/NLP/Weights/eng_classif_RoBerta/Measuring_dat_abuse)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a2f7fa816f78>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_class_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     trainer = train_model(train_dataset,\n\u001b[0m\u001b[1;32m     21\u001b[0m                           \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                           \u001b[0mtok_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-10a43011f169>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, valid_dataset, tok_len, class_weights, output_dir, learning_rate, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No checkpoints found. training from scratch...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2534\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2536\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2537\u001b[0m                     ):\n\u001b[1;32m   2538\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["dir = \"/content/drive/MyDrive/NLP/\"\n","dataset_dir = dir + \"Data/\"\n","# datasets = [\"CAD_hate\", \"CAD_abuse\", \"Founta_hate\", \"Founta_abuse\", \"Davidson_hate\", \"Davidson_abuse\"]\n","# datasets = [\"CAD_hate\", \"CAD_abuse\"]\n","# datasets = [\"CAD_hate\", \"CAD_abuse\", \"Davidson_hate\", \"Davidson_abuse\", \"Dynamic_hate\", \"Measuring_dat_hate\", \"Measuring_dat_abuse\"]\n","datasets = [ \"Measuring_dat_abuse\"]\n","\n","output_dir = dir + \"Weights/eng_classif_RoBerta/\"\n","num_epochs = 5\n","batch_size = 16\n","learning_rate = 5e-5\n","\n","for dataset in datasets:\n","    dd_dir = dataset_dir + dataset\n","    oo_dir = output_dir + dataset\n","\n","    train_dataset, valid_dataset, test_dataset, tok_len = create_datasets(dd_dir)\n","    class_weights = calculate_class_weights(dd_dir)\n","\n","    trainer = train_model(train_dataset,\n","                          valid_dataset,\n","                          tok_len,\n","                          class_weights,\n","                          oo_dir,\n","                          learning_rate,\n","                          num_epochs,\n","                          batch_size)\n","\n","    trainer.save_model(oo_dir)\n","\n","    print(\"Training done, evaluating...\")\n","    valid_preds = np.argmax(trainer.predict(valid_dataset)[0], axis=1) #should be numpy ndarray\n","    valid_labels = np.array(valid_dataset.labels)\n","\n","    cls_report_valid = classification_report(valid_labels, valid_preds, output_dict=True)\n","    pickle.dump(cls_report_valid, open(oo_dir + \"/cls_report_valid.pickle\", \"wb\"))\n","\n","    test_preds = np.argmax(trainer.predict(test_dataset)[0], axis=1)\n","    test_labels = np.array(test_dataset.labels)\n","\n","    cls_report_test = classification_report(test_labels, test_preds, output_dict=True)\n","    pickle.dump(cls_report_test, open(oo_dir + \"/cls_report_test.pickle\", \"wb\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e0425016e0d9448ca5ddee028a1a86cb","eb14b782fc304c08848dc9b7f60ee793","435c7fd037c644c7ae36ae3b85714706","04b92e7105f44b26b133174bb478f9f3","141ed39f44a14f5e9221c7bfeabc87b3","57e9f927434a44b8988be6f3ee11c9bf","0baf62b2b2ab49ee87fc59373ecaf02f","fbb3d93b9d5545ceabc1810e24173e54","3eea562f318c494687c290b8df3d618d","52f197e6de824b068a476c4c60b436df","19160925990b40ce9315762a268fc605","7fc83f175afe488db20ceffc0e1a4d7c","7da7a100a285495f9d1a0b3502ea1863","90bc0519d4464bcebd14031618d24d51","e103d499d5bf48379db409a94f0b01d2","2e95b6eb647b4818b3751da821681cf3","76a354d5797c41a29da09071fbccf75a","1b60bb5feaf54c22ae256b30619c8197","0c604f82b6ae446b8702c034eefdb1c1","646426b63de5445f8ea2b84f08097a36","8dc181759eea4cfebcb60a2e32862c5b","a0b7bc73206f41a9a74b1bbae47bf837","4c7dc2904d374431ad326975737d73a7","d13629a2495d4b66b066d5580100394c","de14dc0a6d594e7ea2dcc4446e913d14","a983146789e240b3bc30ff087b8a17d7","0d87427459e1487881074bf27d440ab5","55346004b7e54be5aac47594ef9ab0b9","aa11b67ee88b4df59111712a6ec545c7","2ea8e34ad7a5402fb59e061c9990b0d0","fba04a5559774cabb29f90aca03aafa3","c85207f6fcae45799242389d0fb38e16","9de06decbf6f4655b6dcb50fe9681dd9","23743fcd44aa41b1843347682f401977","2618421ce14648ffb3980301c2ce0efb","e3fc7831fe334cd7a5429d563ec6dd56","618f09db28e74564bd3ea3a8b7203241","b58c59a2fbff45a49dfcd6eb06dbe439","5ad49c4556424c07b640ecfb17bd50a4","290a559ef4654dcb81d61a967236d2b5","2b6253f73f424104b61904baba38427d","19c50d25abfb4bbb92e8c7c992145190","2aaa0360f484460a986c8ae85b7f601d","f05b6a9bbdc44b529f7b644ea0ee1b0e","93b7c7a880f04bb78baddf4c18443179","b6f35e5299674aa1a4e6413a9ea74a78","841988ced2a14032b07ed5ed4969b60b","fe333090537c4ce9be04e172e5823759","c4e9fe34910847fcbb2d2cb9751cdadb","e765cd2f0c5a47e186e3b7970a9fd03a","9fcc861219694cabb671b2ef92770e0a","5e5ffd38c2ff4f41a50c83694db74b20","c0622b2ba4444d12bb5700b34c88766e","a4101a407ec24dbfac14260f64e30f31","27b4549e302843adb06d67c8470a5888","7d85061f4ca144ddada7623ab26707e9","7bac1d48edbe42898a03ac92ee754f06","35689b1b7bb34ee6a04145f2eadd1d48","5c1b1848e8c3448588a97f34662b80de","e16c9dde23e24a1498e37f989de9cdf4","8da79cdf1c8849acafb926af30409af2","72401ee95e944fd8b8d04584bc0a17d6","b662d20a93cc46eea2ba3d866d48a917","0397a9db2b6a46b9b090eb21f54accac","aa5b3c4473424faf8bbbd12a2b6ca9d5","a18aa919dbb842c8bd4ae3c08725d63d"]},"collapsed":true,"id":"ew3MJP00t-oP","executionInfo":{"status":"ok","timestamp":1742516329400,"user_tz":-60,"elapsed":26765973,"user":{"displayName":"Hakim Arab","userId":"15578416222710480950"}},"outputId":"38b48c0b-9ba2-4dc8-9200-ce838bca95a1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0425016e0d9448ca5ddee028a1a86cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc83f175afe488db20ceffc0e1a4d7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c7dc2904d374431ad326975737d73a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23743fcd44aa41b1843347682f401977"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93b7c7a880f04bb78baddf4c18443179"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["class weights are [0.90415208 1.11857903]\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d85061f4ca144ddada7623ab26707e9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","You are resuming training from a checkpoint trained with 4.48.3 of Transformers but your current version is 4.49.0. This is not recommended and could yield to errors or unwanted behaviors.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhackimou11\u001b[0m (\u001b[33mhackimou11-ens\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.8"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250320_170622-zmljy3nq</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/hackimou11-ens/huggingface/runs/zmljy3nq' target=\"_blank\">/content/drive/MyDrive/NLP/Weights/eng_classif_RoBerta/Measuring_dat_abuse</a></strong> to <a href='https://wandb.ai/hackimou11-ens/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/hackimou11-ens/huggingface' target=\"_blank\">https://wandb.ai/hackimou11-ens/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/hackimou11-ens/huggingface/runs/zmljy3nq' target=\"_blank\">https://wandb.ai/hackimou11-ens/huggingface/runs/zmljy3nq</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33890' max='33890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33890/33890 7:08:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.356100</td>\n","      <td>0.346131</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.374900</td>\n","      <td>0.360741</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.369200</td>\n","      <td>0.366305</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.368100</td>\n","      <td>0.386320</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.338300</td>\n","      <td>0.389345</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.576400</td>\n","      <td>0.607760</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.557000</td>\n","      <td>0.492869</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.381700</td>\n","      <td>0.375013</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.334000</td>\n","      <td>0.405391</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.369200</td>\n","      <td>0.381929</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.314000</td>\n","      <td>0.407053</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.362300</td>\n","      <td>0.372561</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.365300</td>\n","      <td>0.377055</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.396300</td>\n","      <td>0.359749</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.365700</td>\n","      <td>0.364373</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.305100</td>\n","      <td>0.362427</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.356800</td>\n","      <td>0.376759</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.340900</td>\n","      <td>0.400568</td>\n","    </tr>\n","    <tr>\n","      <td>9750</td>\n","      <td>0.369900</td>\n","      <td>0.378115</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.352300</td>\n","      <td>0.393237</td>\n","    </tr>\n","    <tr>\n","      <td>10250</td>\n","      <td>0.408800</td>\n","      <td>0.404489</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.348800</td>\n","      <td>0.353650</td>\n","    </tr>\n","    <tr>\n","      <td>10750</td>\n","      <td>0.325500</td>\n","      <td>0.363642</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.344900</td>\n","      <td>0.378082</td>\n","    </tr>\n","    <tr>\n","      <td>11250</td>\n","      <td>0.314800</td>\n","      <td>0.340138</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.271100</td>\n","      <td>0.367555</td>\n","    </tr>\n","    <tr>\n","      <td>11750</td>\n","      <td>0.313800</td>\n","      <td>0.277024</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.312500</td>\n","      <td>0.312698</td>\n","    </tr>\n","    <tr>\n","      <td>12250</td>\n","      <td>0.258900</td>\n","      <td>0.297258</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.306200</td>\n","      <td>0.306253</td>\n","    </tr>\n","    <tr>\n","      <td>12750</td>\n","      <td>0.294000</td>\n","      <td>0.293434</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.286300</td>\n","      <td>0.290618</td>\n","    </tr>\n","    <tr>\n","      <td>13250</td>\n","      <td>0.257200</td>\n","      <td>0.301364</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.278600</td>\n","      <td>0.271654</td>\n","    </tr>\n","    <tr>\n","      <td>13750</td>\n","      <td>0.183200</td>\n","      <td>0.330093</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.299000</td>\n","      <td>0.339576</td>\n","    </tr>\n","    <tr>\n","      <td>14250</td>\n","      <td>0.275400</td>\n","      <td>0.321560</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.300700</td>\n","      <td>0.340071</td>\n","    </tr>\n","    <tr>\n","      <td>14750</td>\n","      <td>0.284000</td>\n","      <td>0.327458</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.274500</td>\n","      <td>0.316603</td>\n","    </tr>\n","    <tr>\n","      <td>15250</td>\n","      <td>0.261300</td>\n","      <td>0.302855</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>0.264600</td>\n","      <td>0.325050</td>\n","    </tr>\n","    <tr>\n","      <td>15750</td>\n","      <td>0.339300</td>\n","      <td>0.290190</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>0.264600</td>\n","      <td>0.304704</td>\n","    </tr>\n","    <tr>\n","      <td>16250</td>\n","      <td>0.281800</td>\n","      <td>0.308181</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>0.235900</td>\n","      <td>0.323742</td>\n","    </tr>\n","    <tr>\n","      <td>16750</td>\n","      <td>0.218900</td>\n","      <td>0.350930</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>0.272700</td>\n","      <td>0.255018</td>\n","    </tr>\n","    <tr>\n","      <td>17250</td>\n","      <td>0.258100</td>\n","      <td>0.255356</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>0.222900</td>\n","      <td>0.287259</td>\n","    </tr>\n","    <tr>\n","      <td>17750</td>\n","      <td>0.233200</td>\n","      <td>0.275700</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>0.225500</td>\n","      <td>0.267093</td>\n","    </tr>\n","    <tr>\n","      <td>18250</td>\n","      <td>0.246600</td>\n","      <td>0.291847</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>0.217200</td>\n","      <td>0.252987</td>\n","    </tr>\n","    <tr>\n","      <td>18750</td>\n","      <td>0.260700</td>\n","      <td>0.274377</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>0.269200</td>\n","      <td>0.269733</td>\n","    </tr>\n","    <tr>\n","      <td>19250</td>\n","      <td>0.241500</td>\n","      <td>0.279836</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>0.262000</td>\n","      <td>0.287635</td>\n","    </tr>\n","    <tr>\n","      <td>19750</td>\n","      <td>0.263700</td>\n","      <td>0.273350</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>0.233800</td>\n","      <td>0.287617</td>\n","    </tr>\n","    <tr>\n","      <td>20250</td>\n","      <td>0.217400</td>\n","      <td>0.281680</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>0.243500</td>\n","      <td>0.285253</td>\n","    </tr>\n","    <tr>\n","      <td>20750</td>\n","      <td>0.219300</td>\n","      <td>0.265179</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>0.181000</td>\n","      <td>0.310801</td>\n","    </tr>\n","    <tr>\n","      <td>21250</td>\n","      <td>0.237300</td>\n","      <td>0.234432</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>0.180800</td>\n","      <td>0.284591</td>\n","    </tr>\n","    <tr>\n","      <td>21750</td>\n","      <td>0.239400</td>\n","      <td>0.272834</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>0.189600</td>\n","      <td>0.303950</td>\n","    </tr>\n","    <tr>\n","      <td>22250</td>\n","      <td>0.153200</td>\n","      <td>0.281693</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>0.161700</td>\n","      <td>0.279031</td>\n","    </tr>\n","    <tr>\n","      <td>22750</td>\n","      <td>0.163400</td>\n","      <td>0.290422</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>0.168500</td>\n","      <td>0.268707</td>\n","    </tr>\n","    <tr>\n","      <td>23250</td>\n","      <td>0.168100</td>\n","      <td>0.258612</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>0.184300</td>\n","      <td>0.280629</td>\n","    </tr>\n","    <tr>\n","      <td>23750</td>\n","      <td>0.186900</td>\n","      <td>0.267107</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>0.228200</td>\n","      <td>0.247296</td>\n","    </tr>\n","    <tr>\n","      <td>24250</td>\n","      <td>0.158300</td>\n","      <td>0.265254</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>0.178200</td>\n","      <td>0.250531</td>\n","    </tr>\n","    <tr>\n","      <td>24750</td>\n","      <td>0.217800</td>\n","      <td>0.229052</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>0.194300</td>\n","      <td>0.246921</td>\n","    </tr>\n","    <tr>\n","      <td>25250</td>\n","      <td>0.163900</td>\n","      <td>0.280522</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>0.168400</td>\n","      <td>0.296025</td>\n","    </tr>\n","    <tr>\n","      <td>25750</td>\n","      <td>0.186200</td>\n","      <td>0.242432</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>0.164500</td>\n","      <td>0.226206</td>\n","    </tr>\n","    <tr>\n","      <td>26250</td>\n","      <td>0.163000</td>\n","      <td>0.258990</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>0.226200</td>\n","      <td>0.265514</td>\n","    </tr>\n","    <tr>\n","      <td>26750</td>\n","      <td>0.184600</td>\n","      <td>0.254241</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>0.173900</td>\n","      <td>0.236078</td>\n","    </tr>\n","    <tr>\n","      <td>27250</td>\n","      <td>0.149400</td>\n","      <td>0.281210</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>0.171500</td>\n","      <td>0.239931</td>\n","    </tr>\n","    <tr>\n","      <td>27750</td>\n","      <td>0.089600</td>\n","      <td>0.282073</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>0.209700</td>\n","      <td>0.249734</td>\n","    </tr>\n","    <tr>\n","      <td>28250</td>\n","      <td>0.162300</td>\n","      <td>0.249423</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>0.151600</td>\n","      <td>0.251357</td>\n","    </tr>\n","    <tr>\n","      <td>28750</td>\n","      <td>0.158300</td>\n","      <td>0.271008</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>0.134300</td>\n","      <td>0.269238</td>\n","    </tr>\n","    <tr>\n","      <td>29250</td>\n","      <td>0.151000</td>\n","      <td>0.245979</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>0.141400</td>\n","      <td>0.247348</td>\n","    </tr>\n","    <tr>\n","      <td>29750</td>\n","      <td>0.133100</td>\n","      <td>0.251485</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>0.118800</td>\n","      <td>0.264369</td>\n","    </tr>\n","    <tr>\n","      <td>30250</td>\n","      <td>0.106200</td>\n","      <td>0.276200</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>0.162900</td>\n","      <td>0.242808</td>\n","    </tr>\n","    <tr>\n","      <td>30750</td>\n","      <td>0.163100</td>\n","      <td>0.233485</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>0.154600</td>\n","      <td>0.248232</td>\n","    </tr>\n","    <tr>\n","      <td>31250</td>\n","      <td>0.161800</td>\n","      <td>0.243268</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>0.148100</td>\n","      <td>0.260284</td>\n","    </tr>\n","    <tr>\n","      <td>31750</td>\n","      <td>0.147400</td>\n","      <td>0.254791</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>0.148300</td>\n","      <td>0.251922</td>\n","    </tr>\n","    <tr>\n","      <td>32250</td>\n","      <td>0.136900</td>\n","      <td>0.244157</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>0.165000</td>\n","      <td>0.229736</td>\n","    </tr>\n","    <tr>\n","      <td>32750</td>\n","      <td>0.136200</td>\n","      <td>0.261194</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>0.106400</td>\n","      <td>0.263011</td>\n","    </tr>\n","    <tr>\n","      <td>33250</td>\n","      <td>0.169900</td>\n","      <td>0.257605</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>0.122900</td>\n","      <td>0.254408</td>\n","    </tr>\n","    <tr>\n","      <td>33750</td>\n","      <td>0.134100</td>\n","      <td>0.248798</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["resuming from checkpoint...\n","Training done, evaluating...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]}]}